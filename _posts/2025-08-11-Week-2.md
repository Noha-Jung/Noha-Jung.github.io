---
layout: post
title: "Week 2"
subtitle: "Week 2 tomfoolery"
background: "/img/posts/parallel-computing/openai.jpg"
---

# Data science news 
This week, I'll be sharing news on the recently released GPT-5 model from OpenAI. Released 4 days ago from today, GPT-5 is the long awaited successor to the GPT-4 line of models. With new AI models and LLMs seeming to be releasing every other week and records being broken each time, it seems as though the release of this new model from OpenAI isn't quite living up to the excitement people once had the first time capable LLMs were being released. Let's get into the technical aspects, and how it compares to other LLMs out there. First, how does it compare to GPT-4? One major change is the architecture. GPT-5 is a unified system, which means that it uses an efficient system to choose which model suits best for a question, where in GPT-4, the user had to manually choose the model depending on what kind of answer they wanted. Other improvements include quality of coding answers, writing and generally praises or blindly agrees with the user less. Now to comparing it with other LLMs. There's another reason to the lack of excitement. It just wasn't that groundbreaking, in the sense GPT-4 was back when it was released. People are saying that GPT-5 is just a small update due to the dissapointing benchmark scores, where it takes a measly 5th place compared to Gemini 2.5 Pro, Grok 4, and Claude opus 4 models (According to SimpleBench). This isn't to say that GPT-5 is an incapable model, it is still a very powerful model that can be effectively used as a tool for coding, writing and other general questions. With deep learning changing the landscape of the digital world, and the world in general, it will be interesting to see where further reasearch will and what path AI and LLMs will take.

![스크린샷 2025-08-11 224513](\img\posts\parallel-computing\스크린샷 2025-08-11 224513.png)

# Week 2 Reflection
In this week, I had the opportunity to start working with some medical imaging assets data, where I was tasked to do some data cleaning and shaping. I received the dataset to be cleaned, as well as a model dataset to use as a reference when cleaning the data. The data I received was quite messy, with quite a lot of missing data. For example, there were copius amounts of entries with words that didn't belong, and entries in the wrong columns. My task was to make sure to fix these and make the dataset look neater in general. My procedure was to first convert the Excel file to a csv file, then read it on python using pandas. I chose to use pandas, since it was what I am most familiar with, as opposed to editing directly on Excel. It was also an opportunity to exercise my coding muscles again since it has been quite a while using python and working with a dataset. With the help of the pandas documentation, I was able to breeze through with cleaning columns with words that did not belong, and separating columns into two. The main challenge of cleaning this dataset is the lack of knowledge of each feature, and what they mean. Because of this, I was hesitant to start deleting things, and made sure to ask for clarification and objectives. It was good I asked, as I now have a clearer direction on where to go with the cleaning and what not to do. It is still a work in progress, and a new challenge is to determine the method of grading each row entry. There are columns which grade the medical imaging asset which go from 1-5, where I do not have detailed knowledge of how grading is supposed to happen. This will be another question I will need to ask to sort this out. All in all, it was good to work with data again as I get to apply what I've studied and learnt over the past 3+ years.