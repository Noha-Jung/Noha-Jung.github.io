---
layout: post
title: "Week 10"
subtitle: "Week 10 Activities"
background: "/img/posts/parallel-computing/snek.webp"
---

# Data Science News
##### Python or R?
This week we'll take a look at the pros and cons of Python and R for data science, and what sets each other apart. Both languages are extremely popular in the data science field, and it's safe to say that these two languages are the main ones almost all data scientists use. 

It's well known that Python is very well suited for data science due to the extensive specialised libraries that support machine learning, deep learning and data visualisation. R is known for it's focus on statistical computing while also having a very solid data visualisation ability. So which one's better? It is hard to definitively say which language is better over another due to many pros and cons on either side. For example, while R may have the edge on statistical analysis tasks and better data visualisations, it lacks in speed relative to python especially if the code is poorly written. Python may be easier to use and read, but when it comes to handling large sets of data, the performance drops. 

So what to use and when? It all boils down to the nature of the task being completed. The task is more on the statistical side? Choose R. The task is more Deep/Machine Learning focused? Use Python. It is ideal to use the right tools for the right job, and utilise the best of both worlds instead of struggling with a single language.

# Week 10 reflection
This week was a focus on creating a summary report on the dashboards that were created, where I needed to include the findings, challenges and process of creating the dashboards on Power BI. The findings included what was on the dashboards, and an overview for each dashboard was made where I made sure to detail specific numbers and figures. Images of the charts were also included as a reference. As for the challenges section, the challenges I included were getting used to using Power BI, and trying to obtain meaningful insights from a limited dataset. 

The challenge for this week was writing a process on how to create a dashboard from scratch using an Excel file as a data source. As mentioned previously due to my lack of expertise with the software, I was nowhere near confident on creating a clear and concise procedure. To overcome this I went back to the dashboards I've made and began bactracking the steps I took, as well as "re-enacting" the start of creating the dashboard. This process allowed me to explain the procedure in my head in a clearer manner which led to getting a rough outline of the steps. To fill in the gaps, I turned to properley getting to know the function names as well as their purposes. Doing this, I was able to create a simple step by step procedure on creating a dashboard on Power BI.

Next time I need to create a procedure for a process I am not familiar with, I would at the very least get the fundamentals down such as knowing the names of functions and icons rather than jumping straight into backtracking. While the method was effective, because I didn't have a solid grasp on the names and functions I found myself knowing what to do but not being able to properly express it and explain it clearly.

