---
layout: post
title: "Week 1"
subtitle: "Week 1 shenanigans"
background: '/img/posts/parallel-computing/JAX.jpg'
---

# Data science news 
This week, I'll be sharing a new python library I discovered recently called JAX. JAX is a python library developed by Google with contributions from Nvidia, for high performance numerical computing and large scale machine learning. JAX provides a NumPy-esque interface making it easy for users who are familiar with it. Some other key features include: 
<ul>
  <li>Built in Just-In-Time (JIT) compilation via XLA (Accelerated Linear Algebra)</li>
    <ul>
      <li>Python functions are optimized into machine code the first time theyâ€™re run, which speeds up execution especially on CPUs, GPUs, and TPUs by removing Python overhead and fusing operations.</li>
    </ul>
  <li>Efficient evaluation of gradients via automatic differentiation</li>
    <ul>
      <li>Exact derivatives of functions are calculated automatically, without manually doing calculus. Especially useful for optimization and machine learning</li>
    </ul>
  <li>Automatically vectorized to efficiently map them over arrays representing batches of inputs.(Wikipedia)</li>
    <ul>
      <li>JAX can automatically apply a function to each element in a batch (list or array) without you writing a loop (faster/cleaner code).</li>
    </ul>
</ul>

##### So why JAX instead of numpy? (And vice versa)
JAX has a number of things going for it, like the features mentioned above. The main advantage however, is its ability to support array operations on multiple accelerators which includes CPU, GPU, TPU. This capability allows for highly efficient handling of large scale projects and deep learning tasks, leveraging parallel computing to speed things up. So just switch to JAX entirely? Not necessarily. It turns out that NumPy can actually outperform JAX in certain scenarios, where CPU is being used. This boils down to the architechure of each library, since NumPy runs exclusively on CPU (full reason too long for this post). Essentially, while JAX is the new, mostly upgraded toy in the box, whether you choose JAX or NumPy will depend on the use case.

![parallel computing](\img\posts\parallel-computing\parallel computing.png)

# Week 1 Reflection
In this first week, I officially started the internship at Eastern Health. I was put in with the asset management team, where they handle all the assets in Eastern Health. I was never aware such a line of work existed, but the purpose instantly made sense when I learnt of it. In the first day, I was introduced to the facilities and had a brief orientation going over what the team focuses on and a short introduction to asset management and its inner workings. It was a bit to take in as there was a lot more moving parts than I had expected, so it was quite challenging to keep up with the information being presented. To mitigate this, I made sure to ask any clarifying questions I had, and made simple notes to look back on. Thankfully, we were given the orientation powerpoint and some reading material for us to familiarise with asset management, and spent the next few days reading over the key aspects. This enabled me to gain a more detailed and clear understanding of what asset management is about, and how things operate. At the end of the week, we got into a meeting to discuss the type of data we would be dealing with. We were briefly shown small snippets of what the data looked like, and was explained what each feature represented. Although the data seen was brief, I had started to think about how we could apply our data science skills to create meaningful insights. This week introduced me to asset management, and how it could possibly connect with data science.        